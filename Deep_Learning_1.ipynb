{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wV638qksLvE",
        "outputId": "847ef120-c1be-4622-964f-f77f77928a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from sklearn import preprocessing\n",
        "(x_train,y_train),(x_test,y_test)=boston_housing.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape :\", x_train.shape)\n",
        "print(\"Test shape :\", x_test.shape)\n",
        "print(\"Actual Train output :\", y_train.shape)\n",
        "print(\"Actual Test output:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5dleC4VsrDj",
        "outputId": "8214555a-4cf9-41f1-cba5-5159000e0018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape : (404, 13)\n",
            "Test shape : (102, 13)\n",
            "Actual Train output : (404,)\n",
            "Actual Test output: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULaWWwQLs4so",
        "outputId": "ac76f944-652f-44e8-9de7-d37059759d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
              "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
              "        18.72   ])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSZg_JHns62K",
        "outputId": "ff638e82-b7c0-468c-f9a4-f01c18e2166c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=preprocessing.normalize(x_train)\n",
        "x_test=preprocessing.normalize(x_test)"
      ],
      "metadata": {
        "id": "dIG3lmdLtCF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egEYQpqVtHGg",
        "outputId": "3b16449e-1f17-434c-9dcd-316ed3d98692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0024119 , 0.        , 0.01592969, 0.        , 0.00105285,\n",
              "       0.01201967, 0.17945359, 0.00778265, 0.00782786, 0.6007879 ,\n",
              "       0.04109624, 0.77671895, 0.03663436])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyNo93AItG-u",
        "outputId": "bc5ad6c1-3059-453c-c925-fa994f28cfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "def HousePricePredictionModel():\n",
        "    model=Sequential()\n",
        "    model.add(Dense(128,activation='relu',input_shape=(x_train[0].shape)))\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BTS1m01ctGeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "k=4\n",
        "num_val_samples=len(x_train)//k\n",
        "num_epochs=100\n",
        "all_scores=[]"
      ],
      "metadata": {
        "id": "TRFcCkeutGFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HousePricePredictionModel()\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=1, verbose=1, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH2grDFktVBu",
        "outputId": "e0d59f90-23fc-4cbd-f76e-166ced9673e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 288.0987 - mae: 13.0369 - val_loss: 69.8934 - val_mae: 6.2626\n",
            "Epoch 2/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 69.9626 - mae: 5.9524 - val_loss: 61.7169 - val_mae: 5.6497\n",
            "Epoch 3/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 56.2722 - mae: 5.3524 - val_loss: 57.0994 - val_mae: 5.5319\n",
            "Epoch 4/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63.3703 - mae: 5.5257 - val_loss: 60.3936 - val_mae: 5.5399\n",
            "Epoch 5/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 61.3784 - mae: 5.5485 - val_loss: 57.6047 - val_mae: 5.4373\n",
            "Epoch 6/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 74.3096 - mae: 5.8125 - val_loss: 54.4258 - val_mae: 5.3282\n",
            "Epoch 7/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 51.2864 - mae: 4.9368 - val_loss: 52.6672 - val_mae: 5.2457\n",
            "Epoch 8/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 56.4003 - mae: 5.0965 - val_loss: 51.0956 - val_mae: 5.1577\n",
            "Epoch 9/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 62.5006 - mae: 5.4045 - val_loss: 58.7889 - val_mae: 6.0483\n",
            "Epoch 10/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.5450 - mae: 4.7816 - val_loss: 51.2106 - val_mae: 5.0298\n",
            "Epoch 11/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54.3035 - mae: 4.8801 - val_loss: 47.3307 - val_mae: 4.8778\n",
            "Epoch 12/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51.6369 - mae: 4.8934 - val_loss: 47.4712 - val_mae: 4.8071\n",
            "Epoch 13/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55.8888 - mae: 4.9178 - val_loss: 50.5713 - val_mae: 4.9273\n",
            "Epoch 14/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36.4320 - mae: 4.1557 - val_loss: 44.1355 - val_mae: 4.5789\n",
            "Epoch 15/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.8593 - mae: 4.0385 - val_loss: 41.4942 - val_mae: 4.5463\n",
            "Epoch 16/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 38.9852 - mae: 4.2523 - val_loss: 39.0806 - val_mae: 4.3784\n",
            "Epoch 17/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 41.1457 - mae: 4.3351 - val_loss: 38.1051 - val_mae: 4.2482\n",
            "Epoch 18/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 47.2487 - mae: 4.8003 - val_loss: 46.5947 - val_mae: 4.6966\n",
            "Epoch 19/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 33.5633 - mae: 4.1952 - val_loss: 34.4762 - val_mae: 4.0756\n",
            "Epoch 20/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36.5757 - mae: 4.1936 - val_loss: 39.8616 - val_mae: 4.3131\n",
            "Epoch 21/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29.3364 - mae: 3.9727 - val_loss: 39.1283 - val_mae: 5.0420\n",
            "Epoch 22/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.3238 - mae: 3.6370 - val_loss: 33.9919 - val_mae: 4.0410\n",
            "Epoch 23/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.7525 - mae: 3.8761 - val_loss: 33.2470 - val_mae: 3.9683\n",
            "Epoch 24/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 35.9261 - mae: 4.2069 - val_loss: 31.7826 - val_mae: 3.9021\n",
            "Epoch 25/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.1322 - mae: 3.5516 - val_loss: 30.4289 - val_mae: 3.8474\n",
            "Epoch 26/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 34.3305 - mae: 4.2190 - val_loss: 29.3617 - val_mae: 3.8247\n",
            "Epoch 27/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.2623 - mae: 4.3997 - val_loss: 39.1523 - val_mae: 4.2454\n",
            "Epoch 28/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 22.4795 - mae: 3.3827 - val_loss: 36.9272 - val_mae: 4.1114\n",
            "Epoch 29/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 28.0947 - mae: 3.6354 - val_loss: 28.8925 - val_mae: 3.7305\n",
            "Epoch 30/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 32.0735 - mae: 3.9572 - val_loss: 58.0373 - val_mae: 6.7397\n",
            "Epoch 31/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29.3826 - mae: 3.9045 - val_loss: 27.4648 - val_mae: 3.6943\n",
            "Epoch 32/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.1124 - mae: 3.7061 - val_loss: 29.6972 - val_mae: 3.7715\n",
            "Epoch 33/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32.3416 - mae: 4.0614 - val_loss: 31.3156 - val_mae: 3.8618\n",
            "Epoch 34/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 29.4235 - mae: 4.0904 - val_loss: 31.1989 - val_mae: 3.8239\n",
            "Epoch 35/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.0691 - mae: 3.4563 - val_loss: 29.9074 - val_mae: 3.7813\n",
            "Epoch 36/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 35.9459 - mae: 3.8631 - val_loss: 29.8223 - val_mae: 4.2515\n",
            "Epoch 37/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.2193 - mae: 3.2256 - val_loss: 28.3776 - val_mae: 3.7180\n",
            "Epoch 38/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.7862 - mae: 3.5888 - val_loss: 30.1450 - val_mae: 3.8543\n",
            "Epoch 39/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 23.0029 - mae: 3.4912 - val_loss: 26.4373 - val_mae: 3.6644\n",
            "Epoch 40/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 25.6605 - mae: 3.6266 - val_loss: 27.3399 - val_mae: 4.0543\n",
            "Epoch 41/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 23.6211 - mae: 3.4556 - val_loss: 27.5114 - val_mae: 3.7224\n",
            "Epoch 42/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.1689 - mae: 3.4232 - val_loss: 25.3851 - val_mae: 3.7118\n",
            "Epoch 43/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.6406 - mae: 3.3642 - val_loss: 26.9265 - val_mae: 3.6641\n",
            "Epoch 44/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.7424 - mae: 3.1554 - val_loss: 32.5029 - val_mae: 4.0824\n",
            "Epoch 45/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.3410 - mae: 3.2740 - val_loss: 33.7339 - val_mae: 4.0328\n",
            "Epoch 46/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1709 - mae: 3.3343 - val_loss: 37.9186 - val_mae: 4.2127\n",
            "Epoch 47/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 25.6197 - mae: 3.4971 - val_loss: 29.8594 - val_mae: 3.8581\n",
            "Epoch 48/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.7703 - mae: 3.0414 - val_loss: 34.2839 - val_mae: 4.0468\n",
            "Epoch 49/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 21.7247 - mae: 3.1982 - val_loss: 42.3746 - val_mae: 4.4837\n",
            "Epoch 50/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17.9081 - mae: 3.1933 - val_loss: 44.1649 - val_mae: 4.6369\n",
            "Epoch 51/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 24.0986 - mae: 3.3349 - val_loss: 27.1742 - val_mae: 3.6775\n",
            "Epoch 52/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.5380 - mae: 3.2510 - val_loss: 25.6076 - val_mae: 3.6653\n",
            "Epoch 53/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0640 - mae: 3.1246 - val_loss: 33.5358 - val_mae: 4.1623\n",
            "Epoch 54/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.2595 - mae: 3.3888 - val_loss: 29.4885 - val_mae: 3.7995\n",
            "Epoch 55/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.8703 - mae: 3.2604 - val_loss: 30.4197 - val_mae: 3.8346\n",
            "Epoch 56/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.5722 - mae: 3.0542 - val_loss: 31.8236 - val_mae: 3.9701\n",
            "Epoch 57/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.7912 - mae: 3.1008 - val_loss: 26.5354 - val_mae: 3.5898\n",
            "Epoch 58/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9893 - mae: 3.0582 - val_loss: 26.4604 - val_mae: 3.6527\n",
            "Epoch 59/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 20.9577 - mae: 3.2907 - val_loss: 54.5531 - val_mae: 5.7435\n",
            "Epoch 60/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 18.4425 - mae: 3.1340 - val_loss: 28.7649 - val_mae: 3.8664\n",
            "Epoch 61/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 18.2330 - mae: 3.0332 - val_loss: 27.4698 - val_mae: 3.6278\n",
            "Epoch 62/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.9359 - mae: 3.3919 - val_loss: 30.0549 - val_mae: 3.8295\n",
            "Epoch 63/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3452 - mae: 3.3488 - val_loss: 26.9508 - val_mae: 3.5836\n",
            "Epoch 64/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.1523 - mae: 2.9285 - val_loss: 28.0277 - val_mae: 3.6590\n",
            "Epoch 65/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.4816 - mae: 2.7945 - val_loss: 28.6284 - val_mae: 3.6675\n",
            "Epoch 66/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.3219 - mae: 2.9816 - val_loss: 28.4807 - val_mae: 3.7243\n",
            "Epoch 67/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.9088 - mae: 2.9849 - val_loss: 30.3407 - val_mae: 3.8500\n",
            "Epoch 68/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2379 - mae: 2.9363 - val_loss: 29.5816 - val_mae: 3.6906\n",
            "Epoch 69/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 15.7133 - mae: 2.8346 - val_loss: 33.4387 - val_mae: 4.1719\n",
            "Epoch 70/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 14.5808 - mae: 2.7668 - val_loss: 39.3404 - val_mae: 4.4435\n",
            "Epoch 71/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 15.0366 - mae: 2.8896 - val_loss: 30.0039 - val_mae: 3.7805\n",
            "Epoch 72/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.3002 - mae: 3.1547 - val_loss: 38.3502 - val_mae: 4.4376\n",
            "Epoch 73/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.6121 - mae: 2.7450 - val_loss: 26.5428 - val_mae: 3.5343\n",
            "Epoch 74/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8119 - mae: 2.9348 - val_loss: 31.8165 - val_mae: 3.9078\n",
            "Epoch 75/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.3455 - mae: 3.0658 - val_loss: 31.3241 - val_mae: 3.8739\n",
            "Epoch 76/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7294 - mae: 3.1229 - val_loss: 27.7718 - val_mae: 3.6199\n",
            "Epoch 77/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13.9524 - mae: 2.7771 - val_loss: 33.9101 - val_mae: 4.0433\n",
            "Epoch 78/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6155 - mae: 2.9983 - val_loss: 31.0016 - val_mae: 3.8133\n",
            "Epoch 79/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 16.3462 - mae: 2.9800 - val_loss: 29.5064 - val_mae: 3.6862\n",
            "Epoch 80/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18.6173 - mae: 3.1013 - val_loss: 32.6950 - val_mae: 3.9443\n",
            "Epoch 81/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 14.1545 - mae: 2.8433 - val_loss: 31.9169 - val_mae: 4.1133\n",
            "Epoch 82/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.4955 - mae: 3.0123 - val_loss: 32.5362 - val_mae: 3.8325\n",
            "Epoch 83/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.5335 - mae: 2.8414 - val_loss: 34.1167 - val_mae: 4.0289\n",
            "Epoch 84/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13.8664 - mae: 2.7419 - val_loss: 30.2495 - val_mae: 3.6415\n",
            "Epoch 85/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.3356 - mae: 2.8403 - val_loss: 34.3742 - val_mae: 4.0514\n",
            "Epoch 86/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3348 - mae: 2.9863 - val_loss: 29.4101 - val_mae: 3.5995\n",
            "Epoch 87/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9129 - mae: 2.8337 - val_loss: 31.1134 - val_mae: 3.9243\n",
            "Epoch 88/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 18.0886 - mae: 2.9797 - val_loss: 31.3457 - val_mae: 3.8110\n",
            "Epoch 89/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 17.1097 - mae: 2.9388 - val_loss: 31.3934 - val_mae: 3.6944\n",
            "Epoch 90/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 16.7889 - mae: 2.9536 - val_loss: 36.4894 - val_mae: 3.8991\n",
            "Epoch 91/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6775 - mae: 2.9881 - val_loss: 30.6359 - val_mae: 3.7219\n",
            "Epoch 92/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0107 - mae: 2.9843 - val_loss: 29.0325 - val_mae: 3.6713\n",
            "Epoch 93/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.0755 - mae: 3.1215 - val_loss: 27.8300 - val_mae: 3.5321\n",
            "Epoch 94/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.2444 - mae: 3.0230 - val_loss: 34.0711 - val_mae: 3.9951\n",
            "Epoch 95/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.5200 - mae: 2.8417 - val_loss: 29.2615 - val_mae: 3.5030\n",
            "Epoch 96/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.8335 - mae: 2.8364 - val_loss: 38.5664 - val_mae: 4.3214\n",
            "Epoch 97/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.9434 - mae: 2.9153 - val_loss: 27.7506 - val_mae: 3.5976\n",
            "Epoch 98/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 14.6827 - mae: 2.8090 - val_loss: 26.4884 - val_mae: 3.6496\n",
            "Epoch 99/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12.7381 - mae: 2.6863 - val_loss: 29.9943 - val_mae: 3.6262\n",
            "Epoch 100/100\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 16.0709 - mae: 2.8497 - val_loss: 26.4991 - val_mae: 3.5335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = x_test[0]\n",
        "test_input = np.array([test_input])  # Reshape to a 2D array for the model\n",
        "\n",
        "print(\"Actual output:\", y_test[0])\n",
        "print(\"Predicted output:\", model.predict(test_input))"
      ],
      "metadata": {
        "id": "jFZ2lQqztU3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}